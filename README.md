# ğŸš‘ Kvasir-SEG Image Segmentation with U-Net

This repository implements an image segmentation model using the **U-Net** architecture to segment gastrointestinal images from the **Kvasir-SEG** dataset. The model is trained and evaluated using **Dice Score** and **Intersection over Union (IoU)** as performance metrics.

---

## ğŸ“ Project Structure

```
KvasirSeg-Unet/
â”œâ”€â”€ dataset/       # Dataset download and loading scripts
â”œâ”€â”€ model/         # U-Net model definition
â”œâ”€â”€ scripts/       # Training script
â”œâ”€â”€ utils/         # Metrics and visualization utilities
â”œâ”€â”€ models/        # Trained models
â”œâ”€â”€ KvasirSeg-Unet_Demo.ipynb  # Colab demo notebook
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ“¦ Dataset

Download the Kvasir-SEG dataset from [here](https://datasets.simula.no/downloads/kvasir-seg.zip).

Once downloaded, the dataset will be automatically extracted and used for training and validation.

---

## âœ… Requirements

Install all dependencies using:

```bash
pip install -r requirements.txt
```

### Required Packages
- Python 3.x
- PyTorch
- OpenCV
- Albumentations
- tqdm
- scikit-learn
- matplotlib

---

## ğŸš€ Training the Model

To begin training the model:

```bash
python scripts/train.py
```

This script will:
- Download and prepare the dataset (if needed)
- Train the U-Net model on Kvasir-SEG
- Save the trained model to `models/unet_kvasirseg.pth`

---

## ğŸ§  U-Net Architecture

The U-Net model includes:
- **Encoder**: Downsampling path using convolutional layers
- **Bottleneck**: Deepest layer capturing abstract features
- **Decoder**: Upsampling path using transposed convolutions
- **Skip Connections**: Connect encoder features to corresponding decoder layers for better localization

---

## âš™ï¸ Hyperparameters

| Parameter       | Value        |
|----------------|--------------|
| Learning Rate  | 1e-5         |
| Batch Size     | 8            |
| Epochs         | 100          |
| Loss Function  | BCE + Dice   |

---

## ğŸ“Š Evaluation Metrics

- **Dice Coefficient**: Measures overlap between predicted and ground truth masks
- **IoU (Intersection over Union)**: Evaluates segmentation quality

Metrics are printed after each training epoch.

---
## ğŸ”— Pretrained Model

The pre-trained U-Net model for Kvasir-SEG can be downloaded from the link below:

ğŸ‘‰ [Download from Google Drive](https://drive.google.com/drive/folders/1lqBnKEcrdXOJnAPidseO2diU8faGdUK7?usp=sharing)

After downloading, place the `unet_kvasirseg.pth` file in the `models/` directory:

```
KvasirSeg-Unet/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ unet_kvasirseg.pth  â† Place it here
```

## ğŸ“’ Google Colab Demo

You can try the trained model **directly in your browser** via Google Colab without setting anything up locally:

ğŸ‘‰ [**Run on Colab**](https://colab.research.google.com/github/GaurangTari4/KvasirSeg-Unet/blob/master/KvasirSeg_Unet_Demo.ipynb)

This notebook:
- Installs dependencies
- Downloads the Kvasir-SEG dataset
- Loads the pre-trained U-Net model
- Runs inference on sample images
- Visualizes the results

## ğŸ–¼ï¸ Visualization

During training, visualizations are generated (every few epochs or final epoch), including:
- Input Image
- Ground Truth Mask
- Predicted Mask

This helps to monitor the model's learning progress.

---

## ğŸ’¾ Saving the Model

The final trained model is saved to:

```
models/unet_kvasirseg.pth
```

You can later load this model for inference or fine-tuning.

---

## ğŸ™ Acknowledgements

- **Dataset**: [Kvasir-SEG](https://datasets.simula.no/kvasir-seg/) by Simula Research Laboratory  
- **Model**: U-Net introduced in the paper _"U-Net: Convolutional Networks for Biomedical Image Segmentation"_ by Olaf Ronneberger et al. ([arXiv 2015](https://arxiv.org/abs/1505.04597))

---
